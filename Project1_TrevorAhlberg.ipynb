{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90f86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import io\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "path = \"./yelp_dataset/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df00c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"review_stars.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter=\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "sfile.writerow(['business_id','stars','text'])\n",
    "filename_read = os.path.join(path,\"yelp_academic_dataset_review.json\")\n",
    "lineCount = 0\n",
    "\n",
    "with open(filename_read, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        # some special char must be encoded in 'utf-8'\n",
    "        sfile.writerow([row['business_id'],row['stars'],(row['text']).encode('utf-8')])\n",
    "        #lineCount += 1\n",
    "        #if lineCount >= 1000:\n",
    "         #   break;\n",
    "        \n",
    "outfile.close()\n",
    "\n",
    "df_review=pd.read_csv('review_stars.tsv',delimiter=\"\\t\",encoding=\"utf=8\")\n",
    "\n",
    "df_review[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b63dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"business_stars.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter=\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "sfile.writerow(['business_id','stars','review_count'])\n",
    "filename_read = os.path.join(path,\"yelp_academic_dataset_business.json\")\n",
    "lineCount = 0\n",
    "\n",
    "with open(filename_read, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        # some special char must be encoded in 'utf-8'\n",
    "        sfile.writerow([row['business_id'],row['stars'],row['review_count']])\n",
    "        #lineCount += 1\n",
    "        #if lineCount >= 1000:\n",
    "         #   break;\n",
    "        \n",
    "outfile.close()\n",
    "\n",
    "df_business=pd.read_csv('business_stars.tsv',delimiter=\"\\t\",encoding=\"utf=8\")\n",
    "\n",
    "df_business[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(df_business, df_review, on='business_id')\n",
    "\n",
    "df = df[df['review_count'] >= 20]\n",
    "\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9100021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars_x'] = zscore(df['stars_x'])\n",
    "df['stars_y'] = zscore(df['stars_y'])\n",
    "\n",
    "df.drop('review_count', axis=1, inplace=True)\n",
    "\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_agg = df.groupby('business_id')['text'].sum()\n",
    "df_ready_for_sklearn=pd.DataFrame({'business_id': df_review_agg.index, 'all_reviews': df_review_agg.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3810e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = sk_text.TfidfVectorizer(max_features=5000, min_df=2, max_df=40000)\n",
    "matrix = vectorizer.fit_transform(df_ready_for_sklearn.all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data = matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b88cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd459957",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = zscore(df_business[df_business['review_count'] >= 20].stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_data, df_y.stars, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92228038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, input_dim=tfidf_data.shape[1], activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test,y_test), callbacks=[monitor], verbose=2, epochs=1000)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8625df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Measure MSE error.  \n",
    "MSEscore = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(MSEscore))\n",
    "      \n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "RMSEscore = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(RMSEscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598cb47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
